{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Let's create the class Recurrent neural network (RNN) from scratch. We will implement the algorithm using only the minimum library such as NumPy.\n",
    "\n",
    "\n",
    "The implementation of forward propagation is a required task, and the implementation of back-propagation is an advanced task.\n",
    "\n",
    "\n",
    "The name of the class should be ScratchSimpleRNNClassifier. Please refer to the ScratchDeepNeuralNetrowkClassifier created by the previous Sprint for the class structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "Forward propagation simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import exp\n",
    "class SimpleRNN:\n",
    "    def __init__(self, n_output_features = 4) -> None:\n",
    "        self.n_output_feature = n_output_features\n",
    "        pass\n",
    "\n",
    "    def forward(self,X):\n",
    "        ''' NOTE\n",
    "        h is hidden input and also output to next iteration\n",
    "        X have shape (batch_size, n_sequence, n_features)\n",
    "        Weight have shape (n_features, n_nodes) - n_nodes also means output features\n",
    "        We have 2 weights and 2 biases for hidden input and x input\n",
    "        '''\n",
    "        hidden_output = self.init_hidden_output\n",
    "        for x in np.swapaxes(X, 0, 1): # swap axis of batch and sequence since we iterate through sequence!\n",
    "            hidden_output = self._forward_one_sequence(x,hidden_output)\n",
    "        return hidden_output\n",
    "\n",
    "    def _forward_one_sequence(self,X,h):\n",
    "        forward = X @ self.Wx + h @ self.Wh + self.B\n",
    "        return self.tanh(forward)\n",
    "\n",
    "    def tanh(self,x):\n",
    "        return (exp(x) - exp(-x)) / (exp(x) + exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "Experiment of forward propagation with small sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[[1, 2], [2, 3], [3, 4]]])/100 # (batch_size, n_sequences, n_features)\n",
    "w_x = np.array([[1, 3, 5, 7], [3, 5, 7, 8]])/100 # (n_features, n_nodes)\n",
    "w_h = np.array([[1, 3, 5, 7], [2, 4, 6, 8], [3, 5, 7, 8], [4, 6, 8, 10]])/100 # (n_nodes, n_nodes)\n",
    "batch_size = x.shape[0] # 1\n",
    "n_sequences = x.shape[1] # 3\n",
    "n_features = x.shape[2] # 2\n",
    "n_nodes = w_x.shape[1] # 4\n",
    "h = np.zeros((batch_size, n_nodes)) # (batch_size, n_nodes)\n",
    "b = np.array([1, 1, 1, 1]) # (n_nodes,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.79494228, 0.81839002, 0.83939649, 0.85584174]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model\n",
    "rnn = SimpleRNN(n_output_features=n_nodes)\n",
    "rnn.Wx = w_x\n",
    "rnn.Wh = w_h\n",
    "rnn.B = b\n",
    "rnn.init_hidden_output = h\n",
    "rnn.forward(x)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "55df6c543a2bc93cb77d320c4ab60f53fdbb4f5b7faad8829a512095fe95b67f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('ML': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
