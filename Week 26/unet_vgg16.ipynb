{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.layers import ZeroPadding2D\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:43.879310Z",
     "start_time": "2020-03-25T14:39:43.876304Z"
    },
    "id": "vIkOYGv2DwoE"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:44.446808Z",
     "start_time": "2020-03-25T14:39:44.431975Z"
    },
    "id": "jOJnJWs_DwoF"
   },
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEf-Yy_1DwoF"
   },
   "source": [
    "### Data loading & depth merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../Data/Big/small_salt_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:47.676622Z",
     "start_time": "2020-03-25T14:39:47.485724Z"
    },
    "id": "stLTrm3ADwoG",
    "outputId": "26a6a9d4-4e34-4e46-8548-1cad3d40d272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "           id                                           rle_mask\n",
      "0  668b41c03e  5455 1 5556 3 5657 5 5758 7 5859 8 5960 9 6061...\n",
      "1  fa752c35ca  1 9191 9193 100 9295 99 9398 97 9501 95 9604 9...\n",
      "2  73a2f6fb22  1 4 102 6 203 8 304 13 405 19 506 23 607 25 70...\n",
      "3  739a9ab34a                                            10200 2\n",
      "4  a568cc8273  1942 5 2043 8 2144 12 2245 15 2346 18 2446 23 ...\n",
      "\n",
      "test:\n",
      "           id rle_mask\n",
      "0  02337f94a9      1 1\n",
      "1  952563a97e      1 1\n",
      "2  068f7a5267      1 1\n",
      "3  0e8e9e9b41      1 1\n",
      "4  f2f055154d      1 1\n",
      "\n",
      "           id                                           rle_mask    z\n",
      "0  668b41c03e  5455 1 5556 3 5657 5 5758 7 5859 8 5960 9 6061...  659\n",
      "1  fa752c35ca  1 9191 9193 100 9295 99 9398 97 9501 95 9604 9...  300\n",
      "2  73a2f6fb22  1 4 102 6 203 8 304 13 405 19 506 23 607 25 70...  642\n",
      "3  739a9ab34a                                            10200 2  435\n",
      "4  a568cc8273  1942 5 2043 8 2144 12 2245 15 2346 18 2446 23 ...  626\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(f'{DATA_PATH}/train.csv')\n",
    "test = pd.read_csv(f'{DATA_PATH}/sample_submission.csv')\n",
    "depth = pd.read_csv(f'{DATA_PATH}/depths.csv')\n",
    "\n",
    "train_src = f'{DATA_PATH}/train/'\n",
    "\n",
    "print('train:\\n{}'.format(train.head()))\n",
    "print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gw9NF-5DwoH"
   },
   "source": [
    "### Load images and masks, examine random sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:58.581787Z",
     "start_time": "2020-03-25T14:39:50.781893Z"
    },
    "id": "9gr9O_BSDwoI",
    "outputId": "a5537976-5746-4767-98a8-d38f1d23dc52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 101, 101) (1000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(\n",
    "    [cv2.imread(f'{DATA_PATH}/train/images/{x}.png', 0) for x in train.id.tolist()], \n",
    "    dtype=np.uint8) / 255.\n",
    "y_train = np.asarray(\n",
    "    [cv2.imread(f'{DATA_PATH}/train/masks/{x}.png', 0) for x in train.id.tolist()],\n",
    "    dtype=np.uint8) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:08.034054Z",
     "start_time": "2020-03-25T14:40:07.987000Z"
    },
    "id": "I3NApAfFDwoJ"
   },
   "outputs": [],
   "source": [
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Eiqt3qIDwoK"
   },
   "source": [
    "### Prepare data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:35.924796Z",
     "start_time": "2020-03-25T14:40:09.595933Z"
    },
    "id": "qjdFbDqgDwoK",
    "outputId": "b4331d58-f82c-4f43-b628-b9c2175fdf82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 224, 224, 3) (800, 224, 224, 1)\n",
      "(200, 224, 224, 3) (200, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Add channel features\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "    \n",
    "\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "input_size = (224, 224, 3)\n",
    "model = VGG16(weights=None,input_shape = input_size)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Unet VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        padding='same'):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding=padding,\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_vgg16(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    # resnet_50 = ResNet50(input_shape=input_size, include_top=False, pooling=None)\n",
    "    vgg_16 = VGG16(input_shape = input_size)\n",
    "    base_model = vgg_16\n",
    "    # print(base_model.summary())\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder2 = base_model.get_layer('block2_conv2').output # before block 2 pooling, 128\n",
    "    encoder3 = base_model.get_layer('block3_conv3').output # before block 3 pooling, 256\n",
    "    encoder4 = base_model.get_layer('block4_conv3').output # before block 4 pooling, 512\n",
    "    encoder5 = base_model.get_layer('block5_conv3').output # before block 5 pooling, 512\n",
    "\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=512)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=256)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=128)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    output = UpSampling2D()(concat2)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=64)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)            (None, 224, 224, 64)  1792        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)            (None, 224, 224, 64)  36928       block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, 112, 112, 64)  0           block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)            (None, 112, 112, 128) 73856       block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)            (None, 112, 112, 128) 147584      block2_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 56, 56, 128)   0           block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)            (None, 56, 56, 256)   295168      block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)            (None, 56, 56, 256)   590080      block3_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)            (None, 56, 56, 256)   590080      block3_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, 28, 28, 256)   0           block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)            (None, 28, 28, 512)   1180160     block3_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)            (None, 28, 28, 512)   2359808     block4_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)            (None, 28, 28, 512)   2359808     block4_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, 14, 14, 512)   0           block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)            (None, 14, 14, 512)   2359808     block4_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)            (None, 14, 14, 512)   2359808     block5_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)            (None, 14, 14, 512)   2359808     block5_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)            (None, 14, 14, 512)   2359808     block5_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization)  (None, 14, 14, 512)   2048        center_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)       (None, 14, 14, 512)   100352      center_bn1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 14, 14, 512)   0           center_activation1[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)            (None, 14, 14, 256)   1179904     dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization)  (None, 14, 14, 256)   1024        center_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)       (None, 14, 14, 256)   50176       center_bn2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 14, 14, 256)   0           center_activation2[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)            (None, 14, 14, 512)   1180160     dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization)  (None, 14, 14, 512)   2048        center_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)       (None, 14, 14, 512)   100352      center_bn3[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 14, 14, 512)   0           center_activation3[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 14, 14, 512)   0           dropout_1[0][0]                  \n",
      "                                                                   dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 14, 14, 1024)  0           add_1[0][0]                      \n",
      "                                                                   block5_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)          (None, 14, 14, 512)   4719104     concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalization (None, 14, 14, 512)   2048        decoder4_conv1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)     (None, 14, 14, 512)   100352      decoder4_bn1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 14, 14, 512)   0           decoder4_activation1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)          (None, 14, 14, 256)   1179904     dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalization (None, 14, 14, 256)   1024        decoder4_conv2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)     (None, 14, 14, 256)   50176       decoder4_bn2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 14, 14, 256)   0           decoder4_activation2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)          (None, 14, 14, 512)   1180160     dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalization (None, 14, 14, 512)   2048        decoder4_conv3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)     (None, 14, 14, 512)   100352      decoder4_bn3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 14, 14, 512)   0           decoder4_activation3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 14, 14, 512)   0           dropout_4[0][0]                  \n",
      "                                                                   dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)   (None, 28, 28, 512)   0           add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 28, 28, 1024)  0           up_sampling2d_1[0][0]            \n",
      "                                                                   block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)          (None, 28, 28, 256)   2359552     concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalization (None, 28, 28, 256)   1024        decoder3_conv1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)     (None, 28, 28, 256)   200704      decoder3_bn1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 28, 28, 256)   0           decoder3_activation1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)          (None, 28, 28, 128)   295040      dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalization (None, 28, 28, 128)   512         decoder3_conv2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)     (None, 28, 28, 128)   100352      decoder3_bn2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 28, 28, 128)   0           decoder3_activation2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)          (None, 28, 28, 256)   295168      dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalization (None, 28, 28, 256)   1024        decoder3_conv3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)     (None, 28, 28, 256)   200704      decoder3_bn3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 28, 28, 256)   0           decoder3_activation3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, 28, 28, 256)   0           dropout_7[0][0]                  \n",
      "                                                                   dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)   (None, 56, 56, 256)   0           add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 56, 56, 512)   0           up_sampling2d_2[0][0]            \n",
      "                                                                   block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)          (None, 56, 56, 128)   589952      concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalization (None, 56, 56, 128)   512         decoder2_conv1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)     (None, 56, 56, 128)   401408      decoder2_bn1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 56, 56, 128)   0           decoder2_activation1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)          (None, 56, 56, 64)    73792       dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalization (None, 56, 56, 64)    256         decoder2_conv2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)     (None, 56, 56, 64)    200704      decoder2_bn2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 56, 56, 64)    0           decoder2_activation2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)          (None, 56, 56, 128)   73856       dropout_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalization (None, 56, 56, 128)   512         decoder2_conv3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)     (None, 56, 56, 128)   401408      decoder2_bn3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 56, 56, 128)   0           decoder2_activation3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_4 (Add)                      (None, 56, 56, 128)   0           dropout_10[0][0]                 \n",
      "                                                                   dropout_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)   (None, 112, 112, 128) 0           add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 112, 112, 256) 0           up_sampling2d_3[0][0]            \n",
      "                                                                   block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)   (None, 224, 224, 256) 0           concatenate_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)    (None, 224, 224, 64)  147520      up_sampling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormali (None, 224, 224, 64)  256         decoder_output_conv1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PReL (None, 224, 224, 64)  3211264     decoder_output_bn1[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)             (None, 224, 224, 64)  0           decoder_output_activation1[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)    (None, 224, 224, 32)  18464       dropout_13[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormali (None, 224, 224, 32)  128         decoder_output_conv2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PReL (None, 224, 224, 32)  1605632     decoder_output_bn2[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 224, 224, 32)  0           decoder_output_activation2[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)    (None, 224, 224, 64)  18496       dropout_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormali (None, 224, 224, 64)  256         decoder_output_conv3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PReL (None, 224, 224, 64)  3211264     decoder_output_bn3[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)             (None, 224, 224, 64)  0           decoder_output_activation3[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "add_5 (Add)                      (None, 224, 224, 64)  0           dropout_13[0][0]                 \n",
      "                                                                   dropout_15[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "prediction (Conv2D)              (None, 224, 224, 1)   65          add_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 224, 224, 1)   0           prediction[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 40,435,553\n",
      "Trainable params: 40,428,193\n",
      "Non-trainable params: 7,360\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "K.clear_session()\n",
    "\n",
    "model_depth = unet_vgg16(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_vgg16.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "795/800 [============================>.] - ETA: 0s - loss: 0.9877 - my_iou_metric: 0.2172Epoch 00000: val_my_iou_metric improved from -inf to 0.24500, saving model to unet_vgg16.h5\n",
      "800/800 [==============================] - 110s - loss: 0.9851 - my_iou_metric: 0.2181 - val_loss: 1.4631 - val_my_iou_metric: 0.2450\n"
     ]
    }
   ],
   "source": [
    "epochs = 1  # 1 epoch for testing only\n",
    "batch_size = 5\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8438f3f039ad5b03d877eb20a30850599e9754b619a1b9ae106c1ee8a5e8dcc4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('tensorflow1-gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
