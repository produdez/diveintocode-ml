{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprint 21 - Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-08-05 21:24:25--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "Resolving ai.stanford.edu... 171.64.68.10\n",
      "Connecting to ai.stanford.edu|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 84125825 (80M) [application/x-gzip]\n",
      "Saving to: 'aclImdb_v1.tar.gz'\n",
      "\n",
      "aclImdb_v1.tar.gz   100%[===================>]  80.23M  2.53MB/s    in 38s     \n",
      "\n",
      "2020-08-05 21:25:03 (2.11 MB/s) - 'aclImdb_v1.tar.gz' saved [84125825/84125825]\n",
      "\n",
      "Large Movie Review Dataset v1.0\n",
      "\n",
      "Overview\n",
      "\n",
      "This dataset contains movie reviews along with their associated binary\n",
      "sentiment polarity labels. It is intended to serve as a benchmark for\n",
      "sentiment classification. This document outlines how the dataset was\n",
      "gathered, and how to use the files provided. \n",
      "\n",
      "Dataset \n",
      "\n",
      "The core dataset contains 50,000 reviews split evenly into 25k train\n",
      "and 25k test sets. The overall distribution of labels is balanced (25k\n",
      "pos and 25k neg). We also include an additional 50,000 unlabeled\n",
      "documents for unsupervised learning. \n",
      "\n",
      "In the entire collection, no more than 30 reviews are allowed for any\n",
      "given movie because reviews for the same movie tend to have correlated\n",
      "ratings. Further, the train and test sets contain a disjoint set of\n",
      "movies, so no significant performance is obtained by memorizing\n",
      "movie-unique terms and their associated with observed labels.  In the\n",
      "labeled train/test sets, a negative review has a score <= 4 out of 10,\n",
      "and a positive review has a score >= 7 out of 10. Thus reviews with\n",
      "more neutral ratings are not included in the train/test sets. In the\n",
      "unsupervised set, reviews of any rating are included and there are an\n",
      "even number of reviews > 5 and <= 5.\n",
      "\n",
      "Files\n",
      "\n",
      "There are two top-level directories [train/, test/] corresponding to\n",
      "the training and test sets. Each contains [pos/, neg/] directories for\n",
      "the reviews with binary labels positive and negative. Within these\n",
      "directories, reviews are stored in text files named following the\n",
      "convention [[id]_[rating].txt] where [id] is a unique id and [rating] is\n",
      "the star rating for that review on a 1-10 scale. For example, the file\n",
      "[test/pos/200_8.txt] is the text for a positive-labeled test set\n",
      "example with unique id 200 and star rating 8/10 from IMDb. The\n",
      "[train/unsup/] directory has 0 for all ratings because the ratings are\n",
      "omitted for this portion of the dataset.\n",
      "\n",
      "We also include the IMDb URLs for each review in a separate\n",
      "[urls_[pos, neg, unsup].txt] file. A review with unique id 200 will\n",
      "have its URL on line 200 of this file. Due the ever-changing IMDb, we\n",
      "are unable to link directly to the review, but only to the movie's\n",
      "review page.\n",
      "\n",
      "In addition to the review text files, we include already-tokenized bag\n",
      "of words (BoW) features that were used in our experiments. These \n",
      "are stored in .feat files in the train/test directories. Each .feat\n",
      "file is in LIBSVM format, an ascii sparse-vector format for labeled\n",
      "data.  The feature indices in these files start from 0, and the text\n",
      "tokens corresponding to a feature index is found in [imdb.vocab]. So a\n",
      "line with 0:7 in a .feat file means the first word in [imdb.vocab]\n",
      "(the) appears 7 times in that review.\n",
      "\n",
      "LIBSVM page for details on .feat file format:\n",
      "http://www.csie.ntu.edu.tw/~cjlin/libsvm/\n",
      "\n",
      "We also include [imdbEr.txt] which contains the expected rating for\n",
      "each token in [imdb.vocab] as computed by (Potts, 2011). The expected\n",
      "rating is a good way to get a sense for the average polarity of a word\n",
      "in the dataset.\n",
      "\n",
      "Citing the dataset\n",
      "\n",
      "When using this dataset please cite our ACL 2011 paper which\n",
      "introduces it. This paper also contains classification results which\n",
      "you may want to compare against.\n",
      "\n",
      "\n",
      "@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
      "  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
      "  title     = {Learning Word Vectors for Sentiment Analysis},\n",
      "  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
      "  month     = {June},\n",
      "  year      = {2011},\n",
      "  address   = {Portland, Oregon, USA},\n",
      "  publisher = {Association for Computational Linguistics},\n",
      "  pages     = {142--150},\n",
      "  url       = {http://www.aclweb.org/anthology/P11-1015}\n",
      "}\n",
      "\n",
      "References\n",
      "\n",
      "Potts, Christopher. 2011. On the negativity of negation. In Nan Li and\n",
      "David Lutz, eds., Proceedings of Semantics and Linguistic Theory 20,\n",
      "636-659.\n",
      "\n",
      "Contact\n",
      "\n",
      "For questions/comments/corrections please contact Andrew Maas\n",
      "amaas@cs.stanford.edu\n"
     ]
    }
   ],
   "source": [
    "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar zxf aclImdb_v1.tar.gz\n",
    "!rm -rf aclImdb/train/unsup\n",
    "!cat aclImdb/README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "train_review = load_files('./aclImdb/train/', encoding='utf-8')\n",
    "x_train, y_train = train_review.data, train_review.target\n",
    "test_review = load_files('./aclImdb/test/', encoding='utf-8')\n",
    "x_test, y_test = test_review.data, test_review.target\n",
    "print(train_review.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : Zero Day leads you to think, even re-think why two boys/young men would do what they did - commit mutual suicide via slaughtering their classmates. It captures what must be beyond a bizarre mode of being for two humans who have decided to withdraw from common civility in order to define their own/mutual world via coupled destruction.<br /><br />It is not a perfect movie but given what money/time the filmmaker and actors had - it is a remarkable product. In terms of explaining the motives and actions of the two young suicide/murderers it is better than 'Elephant' - in terms of being a film that gets under our 'rationalistic' skin it is a far, far better film than almost anything you are likely to see. <br /><br />Flawed but honest with a terrible honesty.\n"
     ]
    }
   ],
   "source": [
    "print(\"x : {}\".format(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_dataset = \\\n",
    "  [\"This movie is very good.\",\n",
    "  \"This film is a good\",\n",
    "  \"Very bad. Very, very bad.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>bad</th>\n",
       "      <th>film</th>\n",
       "      <th>good</th>\n",
       "      <th>is</th>\n",
       "      <th>movie</th>\n",
       "      <th>this</th>\n",
       "      <th>very</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  bad  film  good  is  movie  this  very\n",
       "0  0    0     0     1   1      1     1     1\n",
       "1  1    0     1     1   1      0     1     0\n",
       "2  0    2     0     0   0      0     0     3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(token_pattern=r'(?u)\\b\\w+\\b')\n",
    "bow = (vectorizer.fit_transform(mini_dataset)).toarray()\n",
    "df = pd.DataFrame(bow, columns=vectorizer.get_feature_names())\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a good</th>\n",
       "      <th>bad very</th>\n",
       "      <th>film is</th>\n",
       "      <th>is a</th>\n",
       "      <th>is very</th>\n",
       "      <th>movie is</th>\n",
       "      <th>this film</th>\n",
       "      <th>this movie</th>\n",
       "      <th>very bad</th>\n",
       "      <th>very good</th>\n",
       "      <th>very very</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a good  bad very  film is  is a  is very  movie is  this film  this movie  \\\n",
       "0       0         0        0     0        1         1          0           1   \n",
       "1       1         0        1     1        0         0          1           0   \n",
       "2       0         1        0     0        0         0          0           0   \n",
       "\n",
       "   very bad  very good  very very  \n",
       "0         0          1          0  \n",
       "1         0          0          0  \n",
       "2         2          0          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(2, 2), token_pattern=r'(?u)\\b\\w+\\b')\n",
    "bow_train = (vectorizer.fit_transform(mini_dataset)).toarray()\n",
    "df = pd.DataFrame(bow_train, columns=vectorizer.get_feature_names())\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = 'This movie is SOOOO funny!!!'.split()\n",
    "second = 'What a movie! I never'.split()\n",
    "third = 'best movie ever!!!!! this movie'.split()\n",
    "\n",
    "first = [s.lower().replace('!', '') for s in first]\n",
    "second = [s.lower().replace('!', '') for s in second]\n",
    "third = [s.lower().replace('!', '') for s in third]\n",
    "\n",
    "gram_1_all = first + second + third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is</th>\n",
       "      <th>funny</th>\n",
       "      <th>what</th>\n",
       "      <th>soooo</th>\n",
       "      <th>this</th>\n",
       "      <th>a</th>\n",
       "      <th>i</th>\n",
       "      <th>best</th>\n",
       "      <th>ever</th>\n",
       "      <th>never</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is  funny  what  soooo  this  a  i  best  ever  never  movie\n",
       "0   1      1     0      1     1  0  0     0     0      0      1\n",
       "1   0      0     1      0     0  1  1     0     0      1      1\n",
       "2   0      0     0      0     1  0  0     1     1      0      2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "gram_1 = pd.DataFrame(np.zeros((3, len(set(gram_1_all)))).astype('int'), columns=set(gram_1_all))\n",
    "\n",
    "gram_1_list = [first, second, third]\n",
    "for i, ss in enumerate(gram_1_list):\n",
    "    for s in ss:\n",
    "        n = ss.count(s)\n",
    "        gram_1[s][i] = n\n",
    "        \n",
    "gram_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram_2_all  = []\n",
    "gram_2_list = []\n",
    "for s in gram_1_list:\n",
    "    lis = []\n",
    "    for i in range(len(s)-1):\n",
    "        gram_2_all.append(f'{s[i]} {s[i+1]}')\n",
    "        lis.append(f'{s[i]} {s[i+1]}')\n",
    "    \n",
    "    gram_2_list.append(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i never</th>\n",
       "      <th>best movie</th>\n",
       "      <th>movie ever</th>\n",
       "      <th>ever this</th>\n",
       "      <th>movie is</th>\n",
       "      <th>soooo funny</th>\n",
       "      <th>what a</th>\n",
       "      <th>this movie</th>\n",
       "      <th>is soooo</th>\n",
       "      <th>movie i</th>\n",
       "      <th>a movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i never  best movie  movie ever  ever this  movie is  soooo funny  what a  \\\n",
       "0        0           0           0          0         1            1       0   \n",
       "1        1           0           0          0         0            0       1   \n",
       "2        0           1           1          1         0            0       0   \n",
       "\n",
       "   this movie  is soooo  movie i  a movie  \n",
       "0           1         1        0        0  \n",
       "1           0         0        1        1  \n",
       "2           1         0        0        0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram_2 = pd.DataFrame(np.zeros((3, len(set(gram_2_all)))).astype('int'), columns=set(gram_2_all))\n",
    "\n",
    "for i, ss in enumerate(gram_2_list):\n",
    "    for s in ss:\n",
    "        n = ss.count(s)\n",
    "        gram_2[s][i] = n\n",
    "        \n",
    "gram_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "n_samples = 25000\n",
    "idf = np.log(n_samples/np.arange(1,n_samples))\n",
    "plt.title(\"IDF\")\n",
    "plt.xlabel(\"df(t)\")\n",
    "plt.ylabel(\"IDF\")\n",
    "plt.plot(idf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>bad</th>\n",
       "      <th>film</th>\n",
       "      <th>good</th>\n",
       "      <th>movie</th>\n",
       "      <th>this</th>\n",
       "      <th>very</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  bad  film  good  movie  this  very\n",
       "0  0    0     0     1      1     1     1\n",
       "1  1    0     1     1      0     1     0\n",
       "2  0    2     0     0      0     0     3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=[\"is\"], token_pattern=r'\\b\\w+\\b')\n",
    "bow_train = (vectorizer.fit_transform(mini_dataset)).toarray()\n",
    "df = pd.DataFrame(bow_train, columns=vectorizer.get_feature_names())\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/diopmouhamed/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop word : ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "#NLTK\n",
    "import nltk\n",
    "stop_words = nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "print(\"stop word : {}\".format(stop_words)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>good</th>\n",
       "      <th>is</th>\n",
       "      <th>this</th>\n",
       "      <th>very</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bad  good  is  this  very\n",
       "0    0     1   1     1     1\n",
       "1    0     1   1     1     0\n",
       "2    2     0   0     0     3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b', max_features = 5)\n",
    "bow_train = (vectorizer.fit_transform(mini_dataset)).toarray()\n",
    "df = pd.DataFrame(bow_train, columns=vectorizer.get_feature_names())\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 5000) (25000, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer_train = TfidfVectorizer(stop_words=stop_words, max_features=5000)\n",
    "X_train = (vectorizer_train.fit_transform(x_train))\n",
    "vec = vectorizer_train.get_feature_names()\n",
    "\n",
    "vectorizer_test = TfidfVectorizer(stop_words=stop_words,\n",
    "                                  max_features=5000,\n",
    "                                  vocabulary=vec)\n",
    "X_test = vectorizer_test.fit_transform(x_test)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgb = lgb.LGBMClassifier().fit(X_train,y_train)\n",
    "y_pred = lgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86004\n",
      "0.853118870145155\n",
      "0.86984\n",
      "0.8613982966924144\n",
      "[[10628  1872]\n",
      " [ 1627 10873]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"{}\".format(lgb.score(X_test, y_test)))\n",
    "print(\"{}\".format(precision_score(y_test,y_pred)))\n",
    "print(\"{}\".format(recall_score(y_test,y_pred)))\n",
    "print(\"{}\".format(f1_score(y_test,y_pred)))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Standard Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diopmouhamed/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "tf = gram_1.copy()\n",
    "idf = gram_1.copy()\n",
    "\n",
    "for i in range(len(tf)):\n",
    "    tf.iloc[i, :] = tf.iloc[i, :] / tf.iloc[i, :].sum()\n",
    "    \n",
    "for t in idf.columns:\n",
    "    idf[t][:] = np.log(len(idf.columns) / idf[t].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is</th>\n",
       "      <th>funny</th>\n",
       "      <th>what</th>\n",
       "      <th>soooo</th>\n",
       "      <th>this</th>\n",
       "      <th>a</th>\n",
       "      <th>i</th>\n",
       "      <th>best</th>\n",
       "      <th>ever</th>\n",
       "      <th>never</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    is  funny  what  soooo  this    a    i  best  ever  never  movie\n",
       "0  0.2    0.2   0.0    0.2   0.2  0.0  0.0   0.0   0.0    0.0    0.2\n",
       "1  0.0    0.0   0.2    0.0   0.0  0.2  0.2   0.0   0.0    0.2    0.2\n",
       "2  0.0    0.0   0.0    0.0   0.2  0.0  0.0   0.2   0.2    0.0    0.4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is</th>\n",
       "      <th>funny</th>\n",
       "      <th>what</th>\n",
       "      <th>soooo</th>\n",
       "      <th>this</th>\n",
       "      <th>a</th>\n",
       "      <th>i</th>\n",
       "      <th>best</th>\n",
       "      <th>ever</th>\n",
       "      <th>never</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>1.704748</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>1.011601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>1.704748</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>1.011601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>1.704748</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>1.011601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         is     funny      what     soooo      this         a         i  \\\n",
       "0  2.397895  2.397895  2.397895  2.397895  1.704748  2.397895  2.397895   \n",
       "1  2.397895  2.397895  2.397895  2.397895  1.704748  2.397895  2.397895   \n",
       "2  2.397895  2.397895  2.397895  2.397895  1.704748  2.397895  2.397895   \n",
       "\n",
       "       best      ever     never     movie  \n",
       "0  2.397895  2.397895  2.397895  1.011601  \n",
       "1  2.397895  2.397895  2.397895  1.011601  \n",
       "2  2.397895  2.397895  2.397895  1.011601  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is</th>\n",
       "      <th>funny</th>\n",
       "      <th>what</th>\n",
       "      <th>soooo</th>\n",
       "      <th>this</th>\n",
       "      <th>a</th>\n",
       "      <th>i</th>\n",
       "      <th>best</th>\n",
       "      <th>ever</th>\n",
       "      <th>never</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.479579</td>\n",
       "      <td>0.479579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.479579</td>\n",
       "      <td>0.34095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.479579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.479579</td>\n",
       "      <td>0.479579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.479579</td>\n",
       "      <td>0.20232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.34095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.479579</td>\n",
       "      <td>0.479579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.40464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         is     funny      what     soooo     this         a         i  \\\n",
       "0  0.479579  0.479579  0.000000  0.479579  0.34095  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.479579  0.000000  0.00000  0.479579  0.479579   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.34095  0.000000  0.000000   \n",
       "\n",
       "       best      ever     never    movie  \n",
       "0  0.000000  0.000000  0.000000  0.20232  \n",
       "1  0.000000  0.000000  0.479579  0.20232  \n",
       "2  0.479579  0.479579  0.000000  0.40464  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf * idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Formula adopted by scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diopmouhamed/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "tf_2 = gram_1.copy()\n",
    "idf_2 = gram_1.copy()\n",
    "\n",
    "for t in idf.columns:\n",
    "    idf_2[t][:] = np.log((1 + len(idf_2.columns)) / (1 + idf[t].sum())) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is</th>\n",
       "      <th>funny</th>\n",
       "      <th>what</th>\n",
       "      <th>soooo</th>\n",
       "      <th>this</th>\n",
       "      <th>a</th>\n",
       "      <th>i</th>\n",
       "      <th>best</th>\n",
       "      <th>ever</th>\n",
       "      <th>never</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.381543</td>\n",
       "      <td>1.381543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.381543</td>\n",
       "      <td>1.674285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.089949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.381543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.381543</td>\n",
       "      <td>1.381543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.381543</td>\n",
       "      <td>2.089949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.674285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.381543</td>\n",
       "      <td>1.381543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.179898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         is     funny      what     soooo      this         a         i  \\\n",
       "0  1.381543  1.381543  0.000000  1.381543  1.674285  0.000000  0.000000   \n",
       "1  0.000000  0.000000  1.381543  0.000000  0.000000  1.381543  1.381543   \n",
       "2  0.000000  0.000000  0.000000  0.000000  1.674285  0.000000  0.000000   \n",
       "\n",
       "       best      ever     never     movie  \n",
       "0  0.000000  0.000000  0.000000  2.089949  \n",
       "1  0.000000  0.000000  1.381543  2.089949  \n",
       "2  1.381543  1.381543  0.000000  4.179898  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_2 * idf_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/cf/87b25b265d23498b2b70ce873495cf7ef91394c4baff240210e26f3bc18a/gensim-3.8.3-cp37-cp37m-macosx_10_9_x86_64.whl (24.2MB)\n",
      "\u001b[K     || 24.2MB 3.9MB/s eta 0:00:01    |                        | 5.8MB 98kB/s eta 0:03:06     |    | 21.0MB 3.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /Users/diopmouhamed/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/diopmouhamed/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages (from gensim) (1.18.4)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/8e/464b06f5efd26f2dc16ce7bd1662c2f31cadf9104fdbcbf5994674cc3a51/smart_open-2.1.0.tar.gz (116kB)\n",
      "\u001b[K     || 122kB 1.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5.0 in /Users/diopmouhamed/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: requests in /Users/diopmouhamed/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied: boto in /Users/diopmouhamed/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Collecting boto3 (from smart-open>=1.8.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/50/e9c3b7a5b0e06f9b3818074400f83482063c582bd2f5af799adecbd0b0cd/boto3-1.14.35-py2.py3-none-any.whl (129kB)\n",
      "\u001b[K     || 133kB 1.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/diopmouhamed/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/diopmouhamed/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/diopmouhamed/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/diopmouhamed/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Collecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.8.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
      "Collecting s3transfer<0.4.0,>=0.3.0 (from boto3->smart-open>=1.8.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
      "\u001b[K     || 71kB 3.4MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting botocore<1.18.0,>=1.17.35 (from boto3->smart-open>=1.8.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/6a/e7008939a4b17d458d976fff0da62167b3c0f2e4015ebea09202261a092a/botocore-1.17.35-py2.py3-none-any.whl (6.5MB)\n",
      "\u001b[K     || 6.5MB 1.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/diopmouhamed/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.35->boto3->smart-open>=1.8.1->gensim) (2.8.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /Users/diopmouhamed/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.35->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-2.1.0-cp37-none-any.whl size=110319 sha256=7f3c82735aaef4a69b71cd22008a69889504f6f06d067d81d003ae3b5ecf7f56\n",
      "  Stored in directory: /Users/diopmouhamed/Library/Caches/pip/wheels/25/6c/db/7dcb26f19fb260c5629af85ed1c8ef9641143444fc7ec1fa08\n",
      "Successfully built smart-open\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3, smart-open, gensim\n",
      "Successfully installed boto3-1.14.35 botocore-1.17.35 gensim-3.8.3 jmespath-0.10.0 s3transfer-0.3.3 smart-open-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of vocabulary: dict_keys(['this', 'movie', 'is', 'very', 'good', 'film', 'a', 'bad'])\n",
      "Vector of this : \n",
      "[-0.03846292  0.04551623 -0.03332471 -0.04252932 -0.03062297  0.01650657\n",
      " -0.03368527 -0.03268282  0.02649088 -0.04647775]\n",
      "Vector of movie : \n",
      "[ 0.043164    0.03326549 -0.04342645  0.01879135 -0.02225664 -0.017008\n",
      "  0.01921584 -0.02380458 -0.00926294 -0.04241936]\n",
      "Vector of is : \n",
      "[-0.0261138   0.01805291  0.04664908 -0.010152    0.02375114 -0.03711154\n",
      "  0.01883607  0.0362896  -0.02670297 -0.02779392]\n",
      "Vector of very : \n",
      "[ 0.04006131  0.04334307  0.00686985 -0.04044053 -0.00031693 -0.02255407\n",
      "  0.00060548 -0.04330408  0.00320572 -0.01898312]\n",
      "Vector of good : \n",
      "[ 0.00719756  0.01509543 -0.019727    0.02512015 -0.0084928  -0.01313411\n",
      "  0.04350618  0.02552604  0.04288351  0.04628338]\n",
      "Vector of film : \n",
      "[ 0.0093612  -0.0327603   0.0419189  -0.04767568 -0.01804223  0.00699206\n",
      " -0.02432043  0.00319532 -0.03569939 -0.0135851 ]\n",
      "Vector of a : \n",
      "[-0.00078242 -0.0043831   0.04168001  0.01118625 -0.03136522  0.01687401\n",
      "  0.02995327 -0.02150625 -0.04595294 -0.0181825 ]\n",
      "Vector of bad : \n",
      "[-0.00711582  0.04981611  0.0207276   0.01074316  0.02232581 -0.02616438\n",
      "  0.01578815 -0.00699724 -0.01745077  0.03862879]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diopmouhamed/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "sentences = [['this', 'movie', 'is', 'very', 'good'], ['this', 'film', 'is', 'a', 'good'], ['very', 'bad', 'very', 'very', 'bad']]\n",
    "model = Word2Vec(min_count=1, size=10) \n",
    "model.build_vocab(sentences) \n",
    "model.train(sentences, total_examples=model.corpus_count, epochs=model.iter) \n",
    "print(\"List of vocabulary: {}\".format(model.wv.vocab.keys()))\n",
    "for vocab in model.wv.vocab.keys():\n",
    "    print(\"Vector of {} : \\n{}\".format(vocab, model.wv[vocab]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bad', 0.3160766065120697),\n",
       " ('movie', 0.05001020431518555),\n",
       " ('is', -0.181209534406662)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=\"good\", topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diopmouhamed/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "vocabs = model.wv.vocab.keys()\n",
    "tsne_model = TSNE(perplexity=40, n_components=2, init=\"pca\", n_iter=5000, random_state=23)\n",
    "vectors_tsne = tsne_model.fit_transform(model[vocabs])\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.scatter(vectors_tsne[:, 0], vectors_tsne[:, 1])\n",
    "for i, word in enumerate(list(vocabs)):\n",
    "    plt.annotate(word, xy=(vectors_tsne[i, 0], vectors_tsne[i, 1]))\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "I don't hand out \"ones\" often, but if there was ever a film that deserved this sort of attention, it's \"Gas!\" This is self-indulgent crap that reaches for some of the ambiance of M*A*S*H and falls completely flat on its face in the attempt.<br /><br />I see what Corman was going for - Malcolm Marmorstein and Elliott Gould tried to reproduce Gould's deathless role in the original movie version of M*A*S*H with a similar plot (in the movie \"Whiffs\" - look it up here in IMDb, http://www.imdb.com/title/tt0073891/ for more information).<br /><br />Marmorstein and Gould got closer to the brass ring with \"Whiffs\" than Corman did with \"Gas!\" but didn't quite get there. Neither one of those films even got close to the success of M*A*S*H.<br /><br />What's wrong with \"Gas!\"? What isn't? No one comes close to really acting at a level above junior high school theatrics. The production values stink. Someone else here mentioned the magically regenerating headlights on a getaway car, and there's more of that lack of attention to detail. Nothing works the way it's supposed to in this film, and nobody cares.<br /><br />\"Gas!\" actually put me to sleep. It's not a sure cure for insomnia, but really close. On the Cinematic Sleep Induction scale, \"Gas!\" falls somewhere between \"Last Year at Marienbad\" and George Clooney's remake of \"Solaris\" (which itself was remarkable for being more boring than the Mosfilm original, despite that studio's seeming unfamiliarity with the idea of keeping the audience's attention by judicious editing).<br /><br />Judicious editing would have decimated \"Gas!\" to about twenty minutes. The result would be pointless, but no more so than the original film.<br /><br />Certain films are so bad that they have a compelling quality that makes them worth watching anyway. This isn't one of them. Don't waste your time. It's not even amusingly bad.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "for i, s in enumerate(x_train):\n",
    "    if 'www' in s:\n",
    "        print(i)\n",
    "        print(s)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i dont hand out ones often but if there was ever a film that deserved this sort of attention its gas this is selfindulgent crap that reaches for some of the ambiance of mash and falls completely flat on its face in the attempt  i see what corman was going for  malcolm marmorstein and elliott gould tried to reproduce goulds deathless role in the original movie version of mash with a similar plot in the movie whiffs  look it up here in imdb  for more information  marmorstein and gould got closer to the brass ring with whiffs than corman did with gas but didnt quite get there neither one of those films even got close to the success of mash  whats wrong with gas what isnt no one comes close to really acting at a level above junior high school theatrics the production values stink someone else here mentioned the magically regenerating headlights on a getaway car and theres more of that lack of attention to detail nothing works the way its supposed to in this film and nobody cares  gas actually put me to sleep its not a sure cure for insomnia but really close on the cinematic sleep induction scale gas falls somewhere between last year at marienbad and george clooneys remake of solaris which itself was remarkable for being more boring than the mosfilm original despite that studios seeming unfamiliarity with the idea of keeping the audiences attention by judicious editing  judicious editing would have decimated gas to about twenty minutes the result would be pointless but no more so than the original film  certain films are so bad that they have a compelling quality that makes them worth watching anyway this isnt one of them dont waste your time its not even amusingly bad'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_preprocessing = x_train[38]\n",
    "after_preprocessing1 = re.sub(r'https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-]+', \"\", no_preprocessing) \n",
    "after_preprocessing2 = re.sub(r'<[^>]+>', \" \", after_preprocessing1) \n",
    "after_preprocessing3 = re.sub(r\"[^0-9a-zA-Z ]\", \"\", after_preprocessing2) \n",
    "after_preprocessing = after_preprocessing3.lower() \n",
    "after_preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diopmouhamed/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1390, 8460)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(min_count=1, size=10) \n",
    "model.build_vocab(after_preprocessing) \n",
    "model.train(after_preprocessing, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
